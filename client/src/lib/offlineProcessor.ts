// Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
// ÙŠØ¯ÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙˆØ§Ù„ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø£ÙˆÙ†Ù„Ø§ÙŠÙ† ÙˆØ§Ù„Ø£ÙˆÙÙ„Ø§ÙŠÙ†

import { localDB } from "./localDatabase";

interface ProcessingTask {
  id: string;
  type: "local" | "cloud" | "hybrid";
  service: string;
  imageFile: File;
  prompt: string;
  settings: Record<string, any>;
  priority: number;
  createdAt: number;
}

interface ProcessingResult {
  success: boolean;
  processedImage?: string; // base64
  error?: string;
  processingTime: number;
  metadata: Record<string, any>;
}

interface LocalAIModel {
  id: string;
  name: string;
  size: number;
  capabilities: string[];
  isLoaded: boolean;
  loadTime: number;
  worker?: Worker;
}

// Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
const EMBEDDED_MODELS: Record<string, LocalAIModel> = {
  face_beauty: {
    id: "face_beauty",
    name: "Phi-3 Vision Beauty Filter",
    size: 2.4 * 1024 * 1024 * 1024, // 2.4GB
    capabilities: ["face_enhancement", "beauty_filter", "skin_smoothing"],
    isLoaded: false,
    loadTime: 0,
  },
  bg_remover: {
    id: "bg_remover",
    name: "Segment Anything Model",
    size: 2.6 * 1024 * 1024 * 1024, // 2.6GB
    capabilities: ["background_removal", "object_segmentation"],
    isLoaded: false,
    loadTime: 0,
  },
  super_resolution: {
    id: "super_resolution",
    name: "Real-ESRGAN x4+",
    size: 67 * 1024 * 1024, // 67MB
    capabilities: ["upscaling", "denoising", "sharpening"],
    isLoaded: false,
    loadTime: 0,
  },
  style_transfer: {
    id: "style_transfer",
    name: "Stable Diffusion XL",
    size: 6.9 * 1024 * 1024 * 1024, // 6.9GB
    capabilities: ["style_transfer", "art_generation", "cartoonize"],
    isLoaded: false,
    loadTime: 0,
  },
};

class OfflineProcessor {
  private processingQueue: ProcessingTask[] = [];
  private isProcessing = false;
  private loadedModels: Map<string, LocalAIModel> = new Map();
  private workers: Map<string, Worker> = new Map();
  private connectionStatus: "online" | "offline" | "slow" = "online";

  constructor() {
    this.initializeConnectionMonitoring();
    this.preloadCriticalModels();
  }

  // === Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„ ===
  private initializeConnectionMonitoring() {
    // Ù…Ø±Ø§Ù‚Ø¨Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„
    window.addEventListener("online", () => {
      this.connectionStatus = "online";
      console.log("ğŸŒ Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ù…ØªØ§Ø­ - Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©");
    });

    window.addEventListener("offline", () => {
      this.connectionStatus = "offline";
      console.log("ğŸ“± Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ Ø¥Ù†ØªØ±Ù†Øª - Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©");
    });

    // Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±Ø¹Ø© Ø§Ù„Ø§ØªØµØ§Ù„
    this.checkConnectionSpeed();
  }

  private async checkConnectionSpeed(): Promise<void> {
    try {
      const startTime = performance.now();
      const response = await fetch("/api/ping", {
        method: "HEAD",
        cache: "no-cache",
      });
      const endTime = performance.now();

      const latency = endTime - startTime;

      if (latency > 2000) {
        this.connectionStatus = "slow";
        console.log("ğŸŒ Ø§ØªØµØ§Ù„ Ø¨Ø·ÙŠØ¡ - ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©");
      } else {
        this.connectionStatus = "online";
        console.log("âš¡ Ø§ØªØµØ§Ù„ Ø³Ø±ÙŠØ¹ - Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø© Ù…ØªØ§Ø­Ø©");
      }
    } catch (error) {
      this.connectionStatus = "offline";
      console.log("ğŸ“± Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ - Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙÙ‚Ø·");
    }
  }

  // === ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³Ø¨Ù‚ ===
  private async preloadCriticalModels() {
    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØµØºÙŠØ±Ø© ÙˆØ§Ù„Ù…Ù‡Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹
    const criticalModels = ["super_resolution", "bg_remover"];

    for (const modelId of criticalModels) {
      try {
        await this.loadModel(modelId);
      } catch (error) {
        console.warn(`ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${modelId}:`, error);
      }
    }
  }

  // === Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ===
  private async loadModel(modelId: string): Promise<boolean> {
    if (this.loadedModels.has(modelId)) {
      return true;
    }

    const modelInfo = EMBEDDED_MODELS[modelId];
    if (!modelInfo) {
      throw new Error(`Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: ${modelId}`);
    }

    try {
      const startTime = performance.now();

      // Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø£ÙˆÙ„Ø§Ù‹
      let modelData = await localDB.getCachedModel(modelId);

      if (!modelData) {
        // ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…
        console.log(`ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${modelInfo.name}...`);
        const response = await fetch(`/api/models/${modelId}`);
        if (!response.ok) {
          throw new Error(`ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: ${response.statusText}`);
        }

        modelData = await response.arrayBuffer();

        // Ø­ÙØ¸ ÙÙŠ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù…Ø­Ù„ÙŠ
        await localDB.cacheModel(modelId, modelData, "1.0");
      }

      // Ø¥Ù†Ø´Ø§Ø¡ Worker Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
      const worker = new Worker(
        new URL("../workers/aiModelWorker.ts", import.meta.url),
      );

      // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Worker
      await this.initializeWorker(worker, modelId, modelData);

      const loadTime = performance.now() - startTime;

      const loadedModel: LocalAIModel = {
        ...modelInfo,
        isLoaded: true,
        loadTime,
        worker,
      };

      this.loadedModels.set(modelId, loadedModel);
      this.workers.set(modelId, worker);

      console.log(
        `âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${modelInfo.name} ÙÙŠ ${Math.round(loadTime)}ms`,
      );
      return true;
    } catch (error) {
      console.error(`âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${modelId}:`, error);
      return false;
    }
  }

  private async initializeWorker(
    worker: Worker,
    modelId: string,
    modelData: ArrayBuffer,
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"));
      }, 30000);

      worker.onmessage = (event) => {
        const { type, success, error } = event.data;

        if (type === "model_ready") {
          clearTimeout(timeout);
          if (success) {
            resolve();
          } else {
            reject(new Error(error));
          }
        }
      };

      worker.postMessage({
        type: "load_model",
        modelId,
        modelData,
      });
    });
  }

  // === ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ===
  private determineProcessingType(
    service: string,
    imageSize: number,
  ): "local" | "cloud" | "hybrid" {
    // Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ¹Ù…Ù„ Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¯Ø§Ø¦Ù…Ø§Ù‹
    const localOnlyServices = ["super_resolution", "bg_remover", "face_beauty"];

    // Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ù„Ù„Ø³Ø­Ø§Ø¨Ø©
    const cloudOnlyServices = ["magic_morph", "age_gender_transform"];

    // Ø¹ÙˆØ§Ù…Ù„ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±
    const isLargeImage = imageSize > 10 * 1024 * 1024; // Ø£ÙƒØ¨Ø± Ù…Ù† 10MB
    const isModelLoaded = this.loadedModels.has(service);
    const isOffline = this.connectionStatus === "offline";
    const isSlowConnection = this.connectionStatus === "slow";

    // Ù…Ù†Ø·Ù‚ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±
    if (isOffline) {
      return localOnlyServices.includes(service) ? "local" : "local"; // Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ
    }

    if (localOnlyServices.includes(service) && isModelLoaded) {
      return "local";
    }

    if (cloudOnlyServices.includes(service)) {
      return isSlowConnection && isLargeImage ? "hybrid" : "cloud";
    }

    // Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©
    if (isModelLoaded && (isSlowConnection || isLargeImage)) {
      return "local";
    }

    return "hybrid";
  }

  // === Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‡Ø§Ù… ===
  async processImage(
    service: string,
    imageFile: File,
    prompt: string,
    settings: Record<string, any> = {},
    onProgress?: (progress: number, message: string) => void,
  ): Promise<ProcessingResult> {
    const taskId = `task_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    const task: ProcessingTask = {
      id: taskId,
      type: this.determineProcessingType(service, imageFile.size),
      service,
      imageFile,
      prompt,
      settings,
      priority: settings.priority || 1,
      createdAt: Date.now(),
    };

    onProgress?.(10, `ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: ${task.type}`);

    try {
      switch (task.type) {
        case "local":
          return await this.processLocally(task, onProgress);
        case "cloud":
          return await this.processInCloud(task, onProgress);
        case "hybrid":
          return await this.processHybrid(task, onProgress);
        default:
          throw new Error(`Ù†ÙˆØ¹ Ù…Ø¹Ø§Ù„Ø¬Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: ${task.type}`);
      }
    } catch (error) {
      console.error("ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©:", error);
      return {
        success: false,
        error: error instanceof Error ? error.message : "Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
        processingTime: 0,
        metadata: { taskId, type: task.type },
      };
    }
  }

  // === Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© ===
  private async processLocally(
    task: ProcessingTask,
    onProgress?: (progress: number, message: string) => void,
  ): Promise<ProcessingResult> {
    const startTime = performance.now();

    onProgress?.(20, "ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©...");

    // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    if (!this.loadedModels.has(task.service)) {
      onProgress?.(30, `ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ${task.service}...`);
      const loaded = await this.loadModel(task.service);
      if (!loaded) {
        throw new Error(`ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: ${task.service}`);
      }
    }

    onProgress?.(50, "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ø­Ù„ÙŠØ§Ù‹...");

    const worker = this.workers.get(task.service);
    if (!worker) {
      throw new Error(`Worker ØºÙŠØ± Ù…ØªØ§Ø­ Ù„Ù„Ø®Ø¯Ù…Ø©: ${task.service}`);
    }

    // ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ base64
    const imageBase64 = await this.fileToBase64(task.imageFile);

    // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Worker
    const result = await this.processInWorker(
      worker,
      {
        image: imageBase64,
        prompt: task.prompt,
        settings: task.settings,
      },
      onProgress,
    );

    const processingTime = performance.now() - startTime;

    onProgress?.(95, "Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©...");

    // Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ
    await localDB.saveProcessingHistory({
      originalImage: imageBase64,
      processedImage: result.processedImage,
      prompt: task.prompt,
      service: task.service,
      settings: task.settings,
      timestamp: Date.now(),
      processingTime,
      metadata: { type: "local", taskId: task.id },
    });

    onProgress?.(100, "ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­! âœ¨");

    return {
      success: true,
      processedImage: result.processedImage,
      processingTime,
      metadata: {
        type: "local",
        taskId: task.id,
        modelUsed: task.service,
      },
    };
  }

  // === Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ© ===
  private async processInCloud(
    task: ProcessingTask,
    onProgress?: (progress: number, message: string) => void,
  ): Promise<ProcessingResult> {
    const startTime = performance.now();

    onProgress?.(20, "Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©...");

    const formData = new FormData();
    formData.append("image", task.imageFile);
    formData.append("serviceId", task.service);
    formData.append("settings", JSON.stringify(task.settings));
    formData.append("prompt", task.prompt);

    try {
      const response = await fetch("/api/ai/process", {
        method: "POST",
        body: formData,
      });

      if (!response.ok) {
        throw new Error(`ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©: ${response.statusText}`);
      }

      onProgress?.(50, "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©...");

      // Ù‚Ø±Ø§Ø¡Ø© Server-Sent Events Ù„Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…Ø¨ï¿½ï¿½Ø´Ø±Ø©
      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø§Ø¯Ù…");
      }

      let result: any = null;
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split("\n");

        for (const line of lines) {
          if (line.startsWith("data: ")) {
            try {
              const data = JSON.parse(line.slice(6));

              if (data.type === "progress") {
                onProgress?.(data.progress, data.message);
              } else if (data.type === "completed") {
                result = data;
              } else if (data.type === "error") {
                throw new Error(data.error);
              }
            } catch (parseError) {
              console.warn("ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© SSE:", parseError);
            }
          }
        }
      }

      if (!result || !result.success) {
        throw new Error(result?.error || "ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©");
      }

      const processingTime = performance.now() - startTime;

      onProgress?.(95, "Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©...");

      // Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ
      const originalImageBase64 = await this.fileToBase64(task.imageFile);
      await localDB.saveProcessingHistory({
        originalImage: originalImageBase64,
        processedImage: result.processedImage,
        prompt: task.prompt,
        service: task.service,
        settings: task.settings,
        timestamp: Date.now(),
        processingTime,
        metadata: { type: "cloud", taskId: task.id, ...result.metadata },
      });

      onProgress?.(100, "ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­! â˜ï¸");

      return {
        success: true,
        processedImage: result.processedImage,
        processingTime,
        metadata: {
          type: "cloud",
          taskId: task.id,
          ...result.metadata,
        },
      };
    } catch (error) {
      console.error("ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©:", error);

      // ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©ØŒ Ø¬Ø±Ø¨ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
      if (this.loadedModels.has(task.service)) {
        onProgress?.(30, "ÙØ´Ù„ Ø§Ù„Ø³Ø­Ø§Ø¨Ø© - Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©...");
        return await this.processLocally(task, onProgress);
      }

      throw error;
    }
  }

  // === Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø© ===
  private async processHybrid(
    task: ProcessingTask,
    onProgress?: (progress: number, message: string) => void,
  ): Promise<ProcessingResult> {
    onProgress?.(10, "ØªØ­Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...");

    // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ§Ø­Ø§Ù‹
    if (this.loadedModels.has(task.service)) {
      try {
        onProgress?.(20, "Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©...");
        return await this.processLocally(task, onProgress);
      } catch (error) {
        console.warn("ÙØ´Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©ØŒ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø³Ø­Ø§Ø¨Ø©:", error);
        onProgress?.(50, "Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©...");
      }
    }

    // Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£Ùˆ Ù„Ù… ØªÙƒÙ† Ù…ØªØ§Ø­Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
    return await this.processInCloud(task, onProgress);
  }

  // === Ù…Ø³Ø§Ø¹Ø¯Ø§Øª ===
  private async processInWorker(
    worker: Worker,
    data: any,
    onProgress?: (progress: number, message: string) => void,
  ): Promise<{ processedImage: string }> {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©"));
      }, 120000); // Ù…Ù‡Ù„Ø© Ø¯Ù‚ÙŠÙ‚ØªØ§Ù†

      worker.onmessage = (event) => {
        const { type, success, result, error, progress, message } = event.data;

        if (type === "progress") {
          onProgress?.(progress, message);
        } else if (type === "result") {
          clearTimeout(timeout);
          if (success) {
            resolve(result);
          } else {
            reject(new Error(error));
          }
        }
      };

      worker.postMessage({
        type: "process",
        data,
      });
    });
  }

  private async fileToBase64(file: File): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        // Ø¥Ø²Ø§Ù„Ø© prefix data:image/...;base64,
        const base64 = result.split(",")[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(file);
    });
  }

  // === Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø© ===
  getStatus(): {
    connectionStatus: string;
    loadedModels: string[];
    processingQueueLength: number;
    isProcessing: boolean;
  } {
    return {
      connectionStatus: this.connectionStatus,
      loadedModels: Array.from(this.loadedModels.keys()),
      processingQueueLength: this.processingQueue.length,
      isProcessing: this.isProcessing,
    };
  }

  getModelInfo(modelId: string): LocalAIModel | null {
    return this.loadedModels.get(modelId) || null;
  }

  // === ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ ===
  cleanup(): void {
    this.workers.forEach((worker) => worker.terminate());
    this.workers.clear();
    this.loadedModels.clear();
    this.processingQueue = [];
  }
}

// Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ø´ØªØ±Ùƒ
export const offlineProcessor = new OfflineProcessor();

// ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù†Ø¯ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙØ­Ø©
window.addEventListener("beforeunload", () => {
  offlineProcessor.cleanup();
});

export type { ProcessingTask, ProcessingResult, LocalAIModel };
